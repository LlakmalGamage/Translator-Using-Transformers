{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LlakmalGamage/Translator-Using-Transformers/blob/main/translator_spanish_version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ZG1jv6QSn3"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DAQyTcsEQSn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9hdaqBrQSn5"
      },
      "outputs": [],
      "source": [
        "# german_file_path=\"Data_Sets/deu.txt\"\n",
        "# spanish_file_path=\"Data_Sets/data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNPjKagBQSn6"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store German and English data\n",
        "# german_data = []\n",
        "# english_data = []\n",
        "\n",
        "# with open(german_file_path,'r',encoding='utf-8') as file:\n",
        "#     for line in file:\n",
        "#         english,german,_=line.strip().split('\\t')\n",
        "#         english_data.append(english)\n",
        "#         german_data.append(german)\n",
        "\n",
        "\n",
        "# # Create a DataFrame using Pandas\n",
        "# df = pd.DataFrame({ 'English': english_data , 'German': german_data})\n",
        "\n",
        "# # Display the first few rows of the DataFrame\n",
        "# print(df[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky1x5fPtQSn6"
      },
      "outputs": [],
      "source": [
        "# df_spanish=pd.read_csv(spanish_file_path)\n",
        "\n",
        "# # renaming the names\n",
        "# new_column_names={'english':'English','spanish':'Spanish'}\n",
        "# df_spanish=df_spanish.rename(columns=new_column_names)\n",
        "\n",
        "# print(df_spanish[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw3NktOSQSn6"
      },
      "outputs": [],
      "source": [
        "# file_name=f\"data_german.csv\"\n",
        "\n",
        "# df.to_csv(f\"Data_Sets/{file_name}\",index=False)\n",
        "# print(\"DataFrame saved successfully as\", file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5vkbiDHGQSn6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# current_file_path=\"Data_Sets/data.csv\"\n",
        "# new_file_path=\"Data_Sets/data_spanish.csv\"\n",
        "\n",
        "# os.rename(current_file_path,new_file_path)\n",
        "\n",
        "# print(\"File renamed successfully to\", new_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d0wtq3B3QSn6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# german_file_path=\"data_german.csv\"\n",
        "spanish_file_path=\"data_spanish.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SbXphiEpQSn7"
      },
      "outputs": [],
      "source": [
        "# df1=pd.read_csv(german_file_path)\n",
        "df2=pd.read_csv(spanish_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pnHOhO8BQSn7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "import csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "04BL8ZnsQSn7",
        "outputId": "50e9112e-8d4b-40c8-997d-b7359c19515a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   english              spanish\n",
              "0      Go.                  Ve.\n",
              "1      Go.                Vete.\n",
              "2      Go.                Vaya.\n",
              "3      Go.              Váyase.\n",
              "4      Hi.                Hola.\n",
              "5     Run!              ¡Corre!\n",
              "6     Run.              Corred.\n",
              "7     Who?              ¿Quién?\n",
              "8    Fire!              ¡Fuego!\n",
              "9    Fire!           ¡Incendio!\n",
              "10   Fire!           ¡Disparad!\n",
              "11   Help!              ¡Ayuda!\n",
              "12   Help!  ¡Socorro! ¡Auxilio!\n",
              "13   Help!            ¡Auxilio!\n",
              "14   Jump!              ¡Salta!\n",
              "15   Jump.               Salte.\n",
              "16   Stop!              ¡Parad!\n",
              "17   Stop!               ¡Para!\n",
              "18   Stop!               ¡Pare!\n",
              "19   Wait!             ¡Espera!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a9c5257-0a47-47fc-ad2c-199ebd8d6513\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Ve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Run!</td>\n",
              "      <td>¡Corre!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Corred.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Who?</td>\n",
              "      <td>¿Quién?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>¡Fuego!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>¡Incendio!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>¡Disparad!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Help!</td>\n",
              "      <td>¡Ayuda!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Help!</td>\n",
              "      <td>¡Socorro! ¡Auxilio!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Help!</td>\n",
              "      <td>¡Auxilio!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>¡Salta!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>Salte.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>¡Parad!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>¡Para!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>¡Pare!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>¡Espera!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a9c5257-0a47-47fc-ad2c-199ebd8d6513')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a9c5257-0a47-47fc-ad2c-199ebd8d6513 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a9c5257-0a47-47fc-ad2c-199ebd8d6513');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c24afd19-8a12-461a-867d-5ed2f7c21078\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c24afd19-8a12-461a-867d-5ed2f7c21078')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c24afd19-8a12-461a-867d-5ed2f7c21078 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df2.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o5XBj0NQSn7",
        "outputId": "f8ad9c9f-3595-4767-f84e-c96d47a87ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can't view Flash content on an iPad. However, you can easily email yourself the URLs of these web pages and view that content on your regular computer when you get home.\n",
            "A mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\n",
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
          ]
        }
      ],
      "source": [
        "first_column_values_last_10_rows=df2['english'].tail(10)\n",
        "\n",
        "\n",
        "paragraph = '\\n'.join(first_column_values_last_10_rows)\n",
        "# Print the paragraph\n",
        "print(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFE_SwaSQSn8",
        "outputId": "08c14cf6-fab1-4e4c-ff76-64d1244d0bbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118964"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ZEkhCcQSn8"
      },
      "source": [
        "# Split the English and german translation pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JTexDisnQSn8"
      },
      "outputs": [],
      "source": [
        "#common function for both spanish and german\n",
        "\n",
        "class split_pairs:\n",
        " def split_pairs_method(self,df1):\n",
        "  text_pairs=[]\n",
        "\n",
        "  for i in range(len(df1)):\n",
        "    english,language=df1[\"english\"][i],df1[\"spanish\"][i]\n",
        "    language=\"[start] \" + language + \" [end]\"\n",
        "    text_pairs.append((english,language))\n",
        "\n",
        "  return text_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GxCLV26oQSn8"
      },
      "outputs": [],
      "source": [
        "#randomly selecting that if the above function work\n",
        "class random_pair_test:\n",
        "  def random_test_method(self,text_pairs):\n",
        "   for i in range(3):\n",
        "    print(random.choice(text_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWz-4aHrQSn8",
        "outputId": "9eeeef6c-42b5-4d79-d093-105444d92033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The bag was too heavy for me to carry by myself.', '[start] La bolsa era muy pesada para llevarla yo solo. [end]')\n",
            "('Tom felt uneasy talking to Mary about that matter.', '[start] Tom se sentía incomodo de hablar con Mary acerca de ese asunto. [end]')\n",
            "('I get you.', '[start] Ya te pillo. [end]')\n"
          ]
        }
      ],
      "source": [
        "#pairing for german text\n",
        "\n",
        "spanish_text_pairs=split_pairs().split_pairs_method(df2)\n",
        "\n",
        "random_pair_test().random_test_method(spanish_text_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONBS7oUKQSn8"
      },
      "source": [
        "# Randomizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NMqM0bX4QSn9"
      },
      "outputs": [],
      "source": [
        "random.shuffle(spanish_text_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9jf4gG5QSn9"
      },
      "source": [
        "# Split the data into training, validation,testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fu-sAp4xQSn9"
      },
      "outputs": [],
      "source": [
        "#class for splitting text pairs in to train,test,validation\n",
        "class splitting:\n",
        "    def splitting_method(self,text_pairs):\n",
        "        num_val_sample=int(0.15*len(text_pairs))\n",
        "        num_train_samples=len(text_pairs) - 2 * num_val_sample\n",
        "        train_pairs=text_pairs[:num_train_samples]\n",
        "        val_pairs=text_pairs[num_train_samples:num_train_samples+num_val_sample]\n",
        "        test_pairs=text_pairs[num_train_samples+num_val_sample:]\n",
        "\n",
        "        print(\"Total Sentences: \",len(text_pairs))\n",
        "        print(\"Training set size: \",len(train_pairs))\n",
        "        print(\"Validation set size: \",len(val_pairs))\n",
        "        print(\"Testng set size: \",len(test_pairs))\n",
        "        return train_pairs,val_pairs,test_pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CEDavS5QSn9",
        "outputId": "5aea06e6-d4c6-4457-fede-08b482b50a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences:  118964\n",
            "Training set size:  83276\n",
            "Validation set size:  17844\n",
            "Testng set size:  17844\n"
          ]
        }
      ],
      "source": [
        "spanish_train_pairs,spanish_val_pairs,spanish_test_pairs=splitting().splitting_method(spanish_text_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pOw65VxQSn9",
        "outputId": "df5f0f25-1abf-4a31-d7f0-8e8541d7e6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964\n"
          ]
        }
      ],
      "source": [
        "print(len(spanish_test_pairs)+len(spanish_train_pairs)+len(spanish_val_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1WfhLtQSn9",
        "outputId": "6d3ba85e-c52c-4909-a455-f6621e0ed949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I really like hard boiled eggs.', '[start] Me gustan mucho los huevos duros. [end]')\n"
          ]
        }
      ],
      "source": [
        "print(spanish_val_pairs[200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aBuMqKeQSn9"
      },
      "source": [
        "# Removing Puncuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3VWCgQzrQSn-",
        "outputId": "81e4c877-552b-4357-a4ef-9ffbc8a90308"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "f\"[{re.escape(strip_chars)}]\"\n",
        "\n",
        "f\"{5+3}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC2pkVMvQSn-"
      },
      "source": [
        "# Vectorizing the English and spanish text pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bDTsAh84QSn-"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "    lowercase=tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase,f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size=15000\n",
        "sequence_length=20\n",
        "\n",
        "source_vectorization=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "target_vectorization=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length+1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_english_texts=[pair[0] for pair in spanish_train_pairs]\n",
        "train_spanish_texts=[pair[1] for pair in spanish_train_pairs]\n",
        "\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MOw15MTQSn-",
        "outputId": "b33417d4-daed-477f-b19f-72f6509fccbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monroe received 65 votes.\n",
            "[start] Monroe recibió 65 votos. [end]\n",
            "<keras.src.layers.preprocessing.text_vectorization.TextVectorization object at 0x7fd102471c60>\n"
          ]
        }
      ],
      "source": [
        "print(train_english_texts[1])\n",
        "print(train_spanish_texts[1])\n",
        "\n",
        "print(source_vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5sLgImmQSn-",
        "outputId": "01cf4ef9-152b-4951-f964-5cf9e7209a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Monroe received 65 votes.', '[start] Monroe recibió 65 votos. [end]'), (\"I've lost my strength.\", '[start] Perdí mi fuerza. [end]'), ('As soon as I woke up, the headache returned.', '[start] En cuanto me desperté, volvió el dolor de cabeza. [end]'), ('I was invited by an old friend.', '[start] Me invitó un viejo amigo. [end]')]\n"
          ]
        }
      ],
      "source": [
        "print(spanish_train_pairs[1:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3s0jIZsQSn-"
      },
      "source": [
        "# Preparing datasets for the translation task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t-RDOfPQSn_",
        "outputId": "89d75a81-480d-4c77-eb5d-230ee1ef0ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['spanish'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "batch_size=64\n",
        "\n",
        "def format_dataset(eng,spn):\n",
        "    eng=source_vectorization(eng)\n",
        "    spn=target_vectorization(spn)\n",
        "    return ({\"english\":eng,\n",
        "             \"spanish\":spn[:,:-1],\n",
        "             },spn[:,1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts,spn_texts=zip(*pairs)\n",
        "    eng_texts=list(eng_texts)\n",
        "    spn_texts=list(spn_texts)\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((eng_texts,spn_texts))\n",
        "    dataset=dataset.batch(batch_size)\n",
        "    dataset=dataset.map(format_dataset,num_parallel_calls=4)\n",
        "\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_data=make_dataset(spanish_train_pairs)\n",
        "val_data=make_dataset(spanish_val_pairs)\n",
        "\n",
        "# print(train_data)\n",
        "# print(val_data)\n",
        "\n",
        "for inputs, targets in train_data.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQVEkF7oQSn_",
        "outputId": "6ff4ec55-4174-4849-862a-aa3fba75b4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'english': array([[   3,  388, 1280, ...,    0,    0,    0],\n",
            "       [  12, 9910, 3237, ...,    0,    0,    0],\n",
            "       [  21, 1001,    2, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  87,   18,   63, ...,    0,    0,    0],\n",
            "       [   6,   65,  534, ...,    0,    0,    0],\n",
            "       [  51,  130,   17, ...,    0,    0,    0]]), 'spanish': array([[    2,   510,     6, ...,     0,     0,     0],\n",
            "       [    2,   106, 10356, ...,     0,     0,     0],\n",
            "       [    2,    25,   921, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2,   721,   167, ...,     0,     0,     0],\n",
            "       [    2,     8,     7, ...,     0,     0,     0],\n",
            "       [    2,    27,   453, ...,     0,     0,     0]])}, array([[  510,     6,    31, ...,     0,     0,     0],\n",
            "       [  106, 10356,    22, ...,     0,     0,     0],\n",
            "       [   25,   921,     9, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  721,   167,  1026, ...,     0,     0,     0],\n",
            "       [    8,     7,   135, ...,     0,     0,     0],\n",
            "       [   27,   453,   928, ...,     0,     0,     0]]))\n"
          ]
        }
      ],
      "source": [
        "print(list(train_data.as_numpy_iterator())[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4FpSuqPQSn_"
      },
      "source": [
        "# Transformers encoder implemented as a subclassed Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nyRAeFDgQSn_"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention=layers.MultiHeadAttention(\n",
        "           num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=keras.Sequential(\n",
        "            [layers.Dense(dense_dim,activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "\n",
        "    def call(self,inputs,mask=None):\n",
        "        if mask is not None:\n",
        "            mask=mask[:,tf.newaxis,:]\n",
        "        attention_output=self.attention(\n",
        "            inputs,inputs,attention_mask=mask\n",
        "        )\n",
        "        project_input=self.layernorm_1(inputs+attention_output)\n",
        "        project_output=self.dense_proj(project_input)\n",
        "\n",
        "        return self.layernorm_2(project_input+project_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asuNvD-cQSn_"
      },
      "source": [
        "# Transformer decorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vP9OTqcxQSn_"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention_1=layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.attention_2=layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=keras.Sequential(\n",
        "            [layers.Dense(dense_dim,activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "        self.layernorm_3=layers.LayerNormalization()\n",
        "        self.supports_masking=True\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_casual_attention_mask(self,inputs):\n",
        "        input_shape=tf.shape(inputs)\n",
        "        batch_size,sequence_length=input_shape[0],input_shape[1]\n",
        "        i=tf.range(sequence_length)[:,tf.newaxis]\n",
        "        j=tf.range(sequence_length)\n",
        "        mask=tf.cast(i>=j,dtype=\"int32\")\n",
        "        mask=tf.reshape(mask,(1,input_shape[1],input_shape[1]))\n",
        "        mult=tf.concat(\n",
        "            [tf.expand_dims(batch_size,-1),\n",
        "             tf.constant([1,1],dtype=tf.int32)],axis=0)\n",
        "\n",
        "        return tf.tile(mask,mult)\n",
        "\n",
        "\n",
        "    def call(self,inputs,encorder_outputs,mask=None):\n",
        "        casual_mask=self.get_casual_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask=tf.cast(\n",
        "                mask[:,tf.newaxis,:],dtype=\"int32\"\n",
        "            )\n",
        "            padding_mask=tf.minimum(padding_mask,casual_mask)\n",
        "        else:\n",
        "            padding_mask=mask\n",
        "        attention_output_1=self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=casual_mask\n",
        "        )\n",
        "        attention_output_1=self.layernorm_1(inputs+attention_output_1)\n",
        "        attention_output_2=self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encorder_outputs,\n",
        "            key=encorder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2=self.layernorm_2(\n",
        "            attention_output_1+attention_output_2\n",
        "        )\n",
        "        proj_output=self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2+proj_output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Dt2Pj_QSoA"
      },
      "source": [
        "# Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "W8JH3MDzQSoA"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self,sequence_length,input_dim,output_dim,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings=layers.Embedding(\n",
        "            input_dim=input_dim,output_dim=output_dim)\n",
        "        self.position_embeddings=layers.Embedding(\n",
        "            input_dim=sequence_length,output_dim=output_dim)\n",
        "        self.sequence_length=sequence_length\n",
        "        self.input_dim=input_dim\n",
        "        self.output_dim=output_dim\n",
        "\n",
        "    def call(self,inputs):\n",
        "        length=tf.shape(inputs)[-1]\n",
        "        positions=tf.range(start=0,limit=length,delta=1)\n",
        "        embedded_tokens=self.token_embeddings(inputs)\n",
        "        embedded_positions=self.position_embeddings(positions)\n",
        "\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super(PositionalEmbedding,self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJz24S2XQSoH"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.python.framework.ops import disable_eager_execution\n",
        "# disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZN5UgCOQSoH"
      },
      "source": [
        "# End-to-End Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QYCGfZpwQSoH"
      },
      "outputs": [],
      "source": [
        "embed_dim=256\n",
        "dense_dim=2048\n",
        "num_heads=8\n",
        "\n",
        "encoder_inputs=keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(encoder_inputs)\n",
        "encoder_outputs=TransformerEncoder(embed_dim,dense_dim,num_heads)(x)\n",
        "\n",
        "decorder_inputs=keras.Input(shape=(None,),dtype=\"int64\",name=\"spanish\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(decorder_inputs)\n",
        "x=TransformerDecoder(embed_dim,dense_dim,num_heads)(x,encoder_outputs)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "decorder_outputs=layers.Dense(vocab_size,activation=\"softmax\")(x)\n",
        "transformer_spanish=keras.Model([encoder_inputs,decorder_inputs],decorder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_IQ5KACSRIa",
        "outputId": "a5044b75-7e05-48fc-9e64-941349193c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " spanish (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding_4 (Po  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " positional_embedding_5 (Po  (None, None, 256)            3845120   ['spanish[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Tra  (None, None, 256)            3155456   ['positional_embedding_4[0][0]\n",
            " nsformerEncoder)                                                   ']                            \n",
            "                                                                                                  \n",
            " transformer_decoder_2 (Tra  (None, None, 256)            5259520   ['positional_embedding_5[0][0]\n",
            " nsformerDecoder)                                                   ',                            \n",
            "                                                                     'transformer_encoder_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, None, 256)            0         ['transformer_decoder_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, None, 15000)          3855000   ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer_spanish.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XepQ7qXITPOP"
      },
      "source": [
        "# Training the sequence-to-sequence Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFQ2g7CYSdft",
        "outputId": "0b8b3a52-172c-4610-e9d4-c0a33c274e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1302/1302 [==============================] - 112s 79ms/step - loss: 3.7930 - accuracy: 0.4407 - val_loss: 2.8610 - val_accuracy: 0.5415\n",
            "Epoch 2/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 2.8522 - accuracy: 0.5496 - val_loss: 2.5043 - val_accuracy: 0.5910\n",
            "Epoch 3/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.5544 - accuracy: 0.5933 - val_loss: 2.3742 - val_accuracy: 0.6160\n",
            "Epoch 4/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.3933 - accuracy: 0.6196 - val_loss: 2.3345 - val_accuracy: 0.6260\n",
            "Epoch 5/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 2.2879 - accuracy: 0.6384 - val_loss: 2.2980 - val_accuracy: 0.6333\n",
            "Epoch 6/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 2.2159 - accuracy: 0.6514 - val_loss: 2.2875 - val_accuracy: 0.6376\n",
            "Epoch 7/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 2.1551 - accuracy: 0.6632 - val_loss: 2.2880 - val_accuracy: 0.6428\n",
            "Epoch 8/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 2.0978 - accuracy: 0.6749 - val_loss: 2.2405 - val_accuracy: 0.6536\n",
            "Epoch 9/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 2.0408 - accuracy: 0.6854 - val_loss: 2.2374 - val_accuracy: 0.6540\n",
            "Epoch 10/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.9934 - accuracy: 0.6948 - val_loss: 2.2176 - val_accuracy: 0.6627\n",
            "Epoch 11/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.9540 - accuracy: 0.7012 - val_loss: 2.2201 - val_accuracy: 0.6664\n",
            "Epoch 12/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.9213 - accuracy: 0.7078 - val_loss: 2.2272 - val_accuracy: 0.6667\n",
            "Epoch 13/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8937 - accuracy: 0.7130 - val_loss: 2.2455 - val_accuracy: 0.6659\n",
            "Epoch 14/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8683 - accuracy: 0.7172 - val_loss: 2.2360 - val_accuracy: 0.6692\n",
            "Epoch 15/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8470 - accuracy: 0.7216 - val_loss: 2.2775 - val_accuracy: 0.6631\n",
            "Epoch 16/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8280 - accuracy: 0.7257 - val_loss: 2.2419 - val_accuracy: 0.6714\n",
            "Epoch 17/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8049 - accuracy: 0.7292 - val_loss: 2.3009 - val_accuracy: 0.6697\n",
            "Epoch 18/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7883 - accuracy: 0.7322 - val_loss: 2.2941 - val_accuracy: 0.6682\n",
            "Epoch 19/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.7727 - accuracy: 0.7349 - val_loss: 2.2628 - val_accuracy: 0.6725\n",
            "Epoch 20/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7587 - accuracy: 0.7377 - val_loss: 2.2962 - val_accuracy: 0.6696\n",
            "Epoch 21/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7424 - accuracy: 0.7403 - val_loss: 2.3278 - val_accuracy: 0.6666\n",
            "Epoch 22/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.7252 - accuracy: 0.7434 - val_loss: 2.3240 - val_accuracy: 0.6719\n",
            "Epoch 23/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.7089 - accuracy: 0.7465 - val_loss: 2.3100 - val_accuracy: 0.6744\n",
            "Epoch 24/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6994 - accuracy: 0.7481 - val_loss: 2.3425 - val_accuracy: 0.6731\n",
            "Epoch 25/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.6877 - accuracy: 0.7501 - val_loss: 2.3579 - val_accuracy: 0.6716\n",
            "Epoch 26/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.6751 - accuracy: 0.7529 - val_loss: 2.3561 - val_accuracy: 0.6712\n",
            "Epoch 27/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6617 - accuracy: 0.7551 - val_loss: 2.3754 - val_accuracy: 0.6719\n",
            "Epoch 28/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6509 - accuracy: 0.7570 - val_loss: 2.4090 - val_accuracy: 0.6723\n",
            "Epoch 29/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.6380 - accuracy: 0.7591 - val_loss: 2.4450 - val_accuracy: 0.6645\n",
            "Epoch 30/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6294 - accuracy: 0.7606 - val_loss: 2.4070 - val_accuracy: 0.6748\n",
            "Epoch 31/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6165 - accuracy: 0.7632 - val_loss: 2.4095 - val_accuracy: 0.6737\n",
            "Epoch 32/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.6051 - accuracy: 0.7646 - val_loss: 2.4557 - val_accuracy: 0.6641\n",
            "Epoch 33/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.5930 - accuracy: 0.7676 - val_loss: 2.4416 - val_accuracy: 0.6731\n",
            "Epoch 34/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.5835 - accuracy: 0.7691 - val_loss: 2.4690 - val_accuracy: 0.6722\n",
            "Epoch 35/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.5742 - accuracy: 0.7704 - val_loss: 2.4612 - val_accuracy: 0.6711\n",
            "Epoch 36/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.5641 - accuracy: 0.7722 - val_loss: 2.4930 - val_accuracy: 0.6701\n",
            "Epoch 37/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.5515 - accuracy: 0.7747 - val_loss: 2.5047 - val_accuracy: 0.6745\n",
            "Epoch 38/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.5414 - accuracy: 0.7766 - val_loss: 2.5040 - val_accuracy: 0.6747\n",
            "Epoch 39/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.5282 - accuracy: 0.7785 - val_loss: 2.4905 - val_accuracy: 0.6734\n",
            "Epoch 40/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.5191 - accuracy: 0.7801 - val_loss: 2.5430 - val_accuracy: 0.6711\n",
            "Epoch 41/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.5062 - accuracy: 0.7821 - val_loss: 2.5415 - val_accuracy: 0.6729\n",
            "Epoch 42/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.4984 - accuracy: 0.7842 - val_loss: 2.5803 - val_accuracy: 0.6749\n",
            "Epoch 43/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.4889 - accuracy: 0.7855 - val_loss: 2.5483 - val_accuracy: 0.6742\n",
            "Epoch 44/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.4765 - accuracy: 0.7876 - val_loss: 2.5908 - val_accuracy: 0.6731\n",
            "Epoch 45/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.4680 - accuracy: 0.7889 - val_loss: 2.5994 - val_accuracy: 0.6756\n",
            "Epoch 46/50\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.4572 - accuracy: 0.7907 - val_loss: 2.6538 - val_accuracy: 0.6666\n",
            "Epoch 47/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.4500 - accuracy: 0.7925 - val_loss: 2.5928 - val_accuracy: 0.6762\n",
            "Epoch 48/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.4383 - accuracy: 0.7946 - val_loss: 2.6467 - val_accuracy: 0.6690\n",
            "Epoch 49/50\n",
            "1302/1302 [==============================] - 89s 69ms/step - loss: 1.4285 - accuracy: 0.7957 - val_loss: 2.6188 - val_accuracy: 0.6742\n",
            "Epoch 50/50\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.4164 - accuracy: 0.7984 - val_loss: 2.6402 - val_accuracy: 0.6775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd0906da350>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "transformer_spanish.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "transformer_spanish.fit(train_data,epochs=50,validation_data=val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "C0zjU_ZqagVO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "ger_vocab = target_vectorization.get_vocabulary()\n",
        "ger_index_lookup = dict(zip(range(len(ger_vocab)), ger_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer_spanish([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ger_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PY_wqakzcGB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ca1f03-ff55-414a-bcbe-ff72e46aa8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Where do you think the safest place would be?\n",
            "[start] dónde crees que los días el lugar sería menos [end]  [end] [end] [end] [end] [end] [end]   [end]\n",
            "-\n",
            "I am a big fan of the arts.\n",
            "[start] soy un [UNK] grande en la [UNK] [end]  [end] [end] [end] [end] [end] [end]   [end]  [end]\n",
            "-\n",
            "I fell asleep before my father came home.\n",
            "[start] me quedé dormido antes de que mi padre venga en casa [end]  [end] [end] [end] [end]   \n",
            "-\n",
            "Just because he likes painting doesn't mean he's good at it.\n",
            "[start] en realidad él le gusta compartir no quiere ser bueno así [end]  [end] [end] [end] [end] [end]  [end]\n",
            "-\n",
            "How is that possible?\n",
            "[start] cómo es eso posible [end]  [end] [end] [end] [end] [end] [end]   [end]  [end]   \n",
            "-\n",
            "I'm so confused.\n",
            "[start] estoy tan confundida [end]  [end] [end] [end] [end] [end] [end]    [end]     [end]\n",
            "-\n",
            "I've been preparing.\n",
            "[start] me he estado haciendo [end]  [end] [end] [end] [end] [end] [end]   [end]     [end]\n",
            "-\n",
            "Come home with me.\n",
            "[start] venga a casa conmigo [end]  [end] [end] [end]  [end]        [end] [end]\n",
            "-\n",
            "Sicily's summers are hot.\n",
            "[start] los demás están ocupados se [UNK] [end]  [end] [end] [end] [end]   [end]     [end]\n",
            "-\n",
            "I finished the work yesterday.\n",
            "[start] ayer terminó el trabajo [end]  [end] [end] [end] [end] [end]      [end]   [end]\n",
            "-\n",
            "Tom wished he had had the courage to jump into the river and save the baby that had fallen in.\n",
            "[start] tom intentó construir tuvo que siguió el perro de cruzar el río y el vaso con el bebé [UNK] [end]\n",
            "-\n",
            "Sweating allows the human body to regulate its temperature.\n",
            "[start] la granja estáis [UNK] al [UNK] a la temperatura [end]  [end] [end] [end] [end]     [end]\n",
            "-\n",
            "Quiet down.\n",
            "[start] [UNK] [end]  [end] [end] [end] [end] [end] [end] [end] [end]    [end]  [end]   \n",
            "-\n",
            "If you feed your dog properly, you can increase his lifespan.\n",
            "[start] si le [UNK] bien a tu perro se puede convencer a su [UNK] [end]  [end] [end] [end] [end] [end]\n",
            "-\n",
            "Wet clothes cling to the body.\n",
            "[start] la ropa [UNK] el cuerpo [end]  [end] [end] [end] [end]   [end]      [end]\n",
            "-\n",
            "Keep singing.\n",
            "[start] sigue cantando [end]  [end] [end] [end] [end] [end] [end]    [end]   [end]   \n",
            "-\n",
            "He glanced from one to the other, hoping for an answer.\n",
            "[start] Él quitó una a otra esperanza de tomar la otra [end]  [end] [end] [end] [end] [end]   \n",
            "-\n",
            "The skies are clear.\n",
            "[start] el cielo está claro [end]  [end] [end] [end] [end] [end]   [end]   [end]   [end]\n",
            "-\n",
            "I've heard that from a lot of people.\n",
            "[start] he oído mucha gente de vida [end]  [end] [end] [end] [end] [end] [end] [end]     [end]\n",
            "-\n",
            "I see a queen.\n",
            "[start] veo a una vez [end]  [end] [end] [end] [end]    [end]   [end]   [end]\n"
          ]
        }
      ],
      "source": [
        "ger_eng_texts = [pair[0] for pair in spanish_test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(ger_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_YFgoVCYl_zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be872d0-0b9b-4afa-b946-ce4911d44a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5ERUlhqdmwhn"
      },
      "outputs": [],
      "source": [
        "transformer_spanish.save('/content/drive/My Drive/Translators/spanish_model')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}