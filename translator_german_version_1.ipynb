{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LlakmalGamage/Translator-Using-Transformers/blob/main/translator_german_version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ZG1jv6QSn3"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DAQyTcsEQSn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f9hdaqBrQSn5"
      },
      "outputs": [],
      "source": [
        "# german_file_path=\"Data_Sets/deu.txt\"\n",
        "# spanish_file_path=\"Data_Sets/data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pNPjKagBQSn6"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store German and English data\n",
        "# german_data = []\n",
        "# english_data = []\n",
        "\n",
        "# with open(german_file_path,'r',encoding='utf-8') as file:\n",
        "#     for line in file:\n",
        "#         english,german,_=line.strip().split('\\t')\n",
        "#         english_data.append(english)\n",
        "#         german_data.append(german)\n",
        "\n",
        "\n",
        "# # Create a DataFrame using Pandas\n",
        "# df = pd.DataFrame({ 'English': english_data , 'German': german_data})\n",
        "\n",
        "# # Display the first few rows of the DataFrame\n",
        "# print(df[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ky1x5fPtQSn6"
      },
      "outputs": [],
      "source": [
        "# df_spanish=pd.read_csv(spanish_file_path)\n",
        "\n",
        "# # renaming the names\n",
        "# new_column_names={'english':'English','spanish':'Spanish'}\n",
        "# df_spanish=df_spanish.rename(columns=new_column_names)\n",
        "\n",
        "# print(df_spanish[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lw3NktOSQSn6"
      },
      "outputs": [],
      "source": [
        "# file_name=f\"data_german.csv\"\n",
        "\n",
        "# df.to_csv(f\"Data_Sets/{file_name}\",index=False)\n",
        "# print(\"DataFrame saved successfully as\", file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5vkbiDHGQSn6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# current_file_path=\"Data_Sets/data.csv\"\n",
        "# new_file_path=\"Data_Sets/data_spanish.csv\"\n",
        "\n",
        "# os.rename(current_file_path,new_file_path)\n",
        "\n",
        "# print(\"File renamed successfully to\", new_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d0wtq3B3QSn6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "german_file_path=\"data_german.csv\"\n",
        "# spanish_file_path=\"Data_Sets/data_spanish.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SbXphiEpQSn7"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv(german_file_path)\n",
        "# df2=pd.read_csv(spanish_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pnHOhO8BQSn7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "import csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "04BL8ZnsQSn7",
        "outputId": "8df79cfa-10d9-44c0-9e15-fdc04f8c7770"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   English                    German\n",
              "0      Go.                      Geh.\n",
              "1      Hi.                    Hallo!\n",
              "2      Hi.                Grüß Gott!\n",
              "3     Run!                     Lauf!\n",
              "4     Run.                     Lauf!\n",
              "5     Wow!               Potzdonner!\n",
              "6     Wow!             Donnerwetter!\n",
              "7    Fire!                    Feuer!\n",
              "8    Help!                    Hilfe!\n",
              "9    Help!                  Zu Hülf!\n",
              "10   Stop!                    Stopp!\n",
              "11   Wait!                    Warte!\n",
              "12   Wait.                    Warte.\n",
              "13  Begin.                  Fang an.\n",
              "14  Go on.              Mach weiter.\n",
              "15  Hello!                    Hallo!\n",
              "16  Hurry!               Beeil dich!\n",
              "17  Hurry!                  Schnell!\n",
              "18  I hid.      Ich versteckte mich.\n",
              "19  I hid.  Ich habe mich versteckt."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba3a2bce-5d16-4131-a15b-9d9ce8ccf5b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>German</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Geh.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hallo!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Grüß Gott!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lauf!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run.</td>\n",
              "      <td>Lauf!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Potzdonner!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Donnerwetter!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>Feuer!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Hilfe!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Zu Hülf!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Stop!</td>\n",
              "      <td>Stopp!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Wait!</td>\n",
              "      <td>Warte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Wait.</td>\n",
              "      <td>Warte.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Begin.</td>\n",
              "      <td>Fang an.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>Mach weiter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Hallo!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Hurry!</td>\n",
              "      <td>Beeil dich!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Hurry!</td>\n",
              "      <td>Schnell!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I hid.</td>\n",
              "      <td>Ich versteckte mich.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I hid.</td>\n",
              "      <td>Ich habe mich versteckt.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba3a2bce-5d16-4131-a15b-9d9ce8ccf5b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba3a2bce-5d16-4131-a15b-9d9ce8ccf5b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba3a2bce-5d16-4131-a15b-9d9ce8ccf5b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-055197c9-980a-46bb-b26c-ae657a54889b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-055197c9-980a-46bb-b26c-ae657a54889b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-055197c9-980a-46bb-b26c-ae657a54889b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df1.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o5XBj0NQSn7",
        "outputId": "e37637d2-82e1-45ac-9832-c4324337bb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As a prank, some students let three goats loose inside their school after painting the numbers 1, 2 and 4 on the sides of the goats. The teachers spent most of the day looking for goat number 3.\n",
            "The small crowd at Hiroshima Peace Memorial Park stood for a moment of silence at 8:15 a.m., the exact moment an atomic bomb nicknamed “Little Boy” was dropped from the U.S. warplane Enola Gay.\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\n",
            "Even if some sentences by non-native speakers are good, it's really hard to trust that they are good, so members would be helping us much more by limiting their contributions to sentences in their own native languages.\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\n"
          ]
        }
      ],
      "source": [
        "first_column_values_last_10_rows=df1['English'].tail(10)\n",
        "\n",
        "\n",
        "paragraph = '\\n'.join(first_column_values_last_10_rows)\n",
        "# Print the paragraph\n",
        "print(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFE_SwaSQSn8",
        "outputId": "e70560ec-d2ce-45fc-96ab-64a6d1272763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221533"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(df1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ZEkhCcQSn8"
      },
      "source": [
        "# Split the English and german translation pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JTexDisnQSn8"
      },
      "outputs": [],
      "source": [
        "#common function for both spanish and german\n",
        "\n",
        "class split_pairs:\n",
        " def split_pairs_method(self,df1):\n",
        "  text_pairs=[]\n",
        "\n",
        "  for i in range(len(df1)):\n",
        "    english,language=df1[\"English\"][i],df1[\"German\"][i]\n",
        "    language=\"[start] \" + language + \" [end]\"\n",
        "    text_pairs.append((english,language))\n",
        "\n",
        "  return text_pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GxCLV26oQSn8"
      },
      "outputs": [],
      "source": [
        "#randomly selecting that if the above function work\n",
        "class random_pair_test:\n",
        "  def random_test_method(self,text_pairs):\n",
        "   for i in range(3):\n",
        "    print(random.choice(text_pairs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWz-4aHrQSn8",
        "outputId": "359924af-0eda-42a5-8e6e-26c2d3134f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Tom and Mary both know how to swim.', '[start] Tom und Maria können beide schwimmen. [end]')\n",
            "(\"At five o'clock, there's always a rush.\", '[start] Um fünf Uhr ist immer viel los. [end]')\n",
            "(\"There's a new boy in school.\", '[start] Es gibt einen neuen Jungen in der Schule. [end]')\n"
          ]
        }
      ],
      "source": [
        "#pairing for german text\n",
        "\n",
        "german_text_pairs=split_pairs().split_pairs_method(df1)\n",
        "\n",
        "random_pair_test().random_test_method(german_text_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONBS7oUKQSn8"
      },
      "source": [
        "# Randomizing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NMqM0bX4QSn9"
      },
      "outputs": [],
      "source": [
        "random.shuffle(german_text_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9jf4gG5QSn9"
      },
      "source": [
        "# Split the data into training, validation,testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fu-sAp4xQSn9"
      },
      "outputs": [],
      "source": [
        "#class for splitting text pairs in to train,test,validation\n",
        "class splitting:\n",
        "    def splitting_method(self,text_pairs):\n",
        "        num_val_sample=int(0.15*len(text_pairs))\n",
        "        num_train_samples=len(text_pairs) - 2 * num_val_sample\n",
        "        train_pairs=text_pairs[:num_train_samples]\n",
        "        val_pairs=text_pairs[num_train_samples:num_train_samples+num_val_sample]\n",
        "        test_pairs=text_pairs[num_train_samples+num_val_sample:]\n",
        "\n",
        "        print(\"Total Sentences: \",len(text_pairs))\n",
        "        print(\"Training set size: \",len(train_pairs))\n",
        "        print(\"Validation set size: \",len(val_pairs))\n",
        "        print(\"Testng set size: \",len(test_pairs))\n",
        "        return train_pairs,val_pairs,test_pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CEDavS5QSn9",
        "outputId": "369643ea-d3bc-4820-cbf1-d967048b67fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sentences:  221533\n",
            "Training set size:  155075\n",
            "Validation set size:  33229\n",
            "Testng set size:  33229\n"
          ]
        }
      ],
      "source": [
        "german_train_pairs,german_val_pairs,german_test_pairs=splitting().splitting_method(german_text_pairs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pOw65VxQSn9",
        "outputId": "473d5e13-feef-4b3c-8a21-800b29ef7a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221533\n"
          ]
        }
      ],
      "source": [
        "print(len(german_test_pairs)+len(german_train_pairs)+len(german_val_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1WfhLtQSn9",
        "outputId": "079c161e-e20f-49db-ced6-2d44a7092635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Is anybody here?', '[start] Ist hier jemand? [end]')\n"
          ]
        }
      ],
      "source": [
        "print(german_val_pairs[200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aBuMqKeQSn9"
      },
      "source": [
        "# Removing Puncuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3VWCgQzrQSn-",
        "outputId": "49c081df-3984-452d-8b48-27ddcc665848"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "f\"[{re.escape(strip_chars)}]\"\n",
        "\n",
        "f\"{5+3}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC2pkVMvQSn-"
      },
      "source": [
        "# Vectorizing the English and spanish text pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bDTsAh84QSn-"
      },
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "    lowercase=tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase,f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size=15000\n",
        "sequence_length=20\n",
        "\n",
        "source_vectorization=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "target_vectorization=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length+1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_english_texts=[pair[0] for pair in german_train_pairs]\n",
        "train_german_texts=[pair[1] for pair in german_train_pairs]\n",
        "\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_german_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MOw15MTQSn-",
        "outputId": "e424a460-a79c-4062-da2d-e3d72811d2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's a good thing Tom isn't here.\n",
            "[start] Gut, dass Tom nicht hier ist! [end]\n",
            "<keras.src.layers.preprocessing.text_vectorization.TextVectorization object at 0x7b1a886501f0>\n"
          ]
        }
      ],
      "source": [
        "print(train_english_texts[1])\n",
        "print(train_german_texts[1])\n",
        "\n",
        "print(source_vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5sLgImmQSn-",
        "outputId": "1755971d-ab1c-4722-af89-fb8d3e7eaa0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(\"It's a good thing Tom isn't here.\", '[start] Gut, dass Tom nicht hier ist! [end]'), ('Tom said Mary seemed reluctant to eat what he had cooked for her.', '[start] Tom sagte, dass Maria unwillig schien, das zu essen, was er ihr zubereitet hatte. [end]'), (\"We haven't even discussed it.\", '[start] Wir haben es nicht einmal besprochen. [end]'), (\"You're not asking me, are you?\", '[start] Du fragst nicht etwa mich, oder? [end]')]\n"
          ]
        }
      ],
      "source": [
        "print(german_train_pairs[1:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3s0jIZsQSn-"
      },
      "source": [
        "# Preparing datasets for the translation task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t-RDOfPQSn_",
        "outputId": "390031d7-b345-40e3-db4d-31a8e86d945e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['german'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "batch_size=64\n",
        "\n",
        "def format_dataset(eng,ger):\n",
        "    eng=source_vectorization(eng)\n",
        "    ger=target_vectorization(ger)\n",
        "    return ({\"english\":eng,\n",
        "             \"german\":ger[:,:-1],\n",
        "             },ger[:,1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts,ger_texts=zip(*pairs)\n",
        "    eng_texts=list(eng_texts)\n",
        "    ger_texts=list(ger_texts)\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((eng_texts,ger_texts))\n",
        "    dataset=dataset.batch(batch_size)\n",
        "    dataset=dataset.map(format_dataset,num_parallel_calls=4)\n",
        "\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_data=make_dataset(german_train_pairs)\n",
        "val_data=make_dataset(german_val_pairs)\n",
        "\n",
        "# print(train_data)\n",
        "# print(val_data)\n",
        "\n",
        "for inputs, targets in train_data.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['german'].shape: {inputs['german'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQVEkF7oQSn_",
        "outputId": "f035b211-9baf-4dde-b599-ef9412d53e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'english': array([[  14,   89,    7, ...,    0,    0,    0],\n",
            "       [ 110,  346,    0, ...,    0,    0,    0],\n",
            "       [  11,   25,  296, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  31,  752,    7, ...,    0,    0,    0],\n",
            "       [   2, 1016,  503, ...,    0,    0,    0],\n",
            "       [   6,   57,  733, ...,    0,    0,    0]]), 'german': array([[   2,   12,    7, ...,    0,    0,    0],\n",
            "       [   2,    8,    7, ...,    0,    0,    0],\n",
            "       [   2,  236,    9, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,    4, 3318, ...,    0,    0,    0],\n",
            "       [   2,    5,  918, ...,    0,    0,    0],\n",
            "       [   2,    4,   74, ...,    0,    0,    0]])}, array([[  12,    7,  118, ...,    0,    0,    0],\n",
            "       [   8,    7, 1325, ...,    0,    0,    0],\n",
            "       [ 236,    9,   32, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   4, 3318,   59, ...,    0,    0,    0],\n",
            "       [   5,  918, 2319, ...,    0,    0,    0],\n",
            "       [   4,   74,   43, ...,    0,    0,    0]]))\n"
          ]
        }
      ],
      "source": [
        "print(list(train_data.as_numpy_iterator())[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4FpSuqPQSn_"
      },
      "source": [
        "# Transformers encoder implemented as a subclassed Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nyRAeFDgQSn_"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention=layers.MultiHeadAttention(\n",
        "           num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=keras.Sequential(\n",
        "            [layers.Dense(dense_dim,activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "\n",
        "    def call(self,inputs,mask=None):\n",
        "        if mask is not None:\n",
        "            mask=mask[:,tf.newaxis,:]\n",
        "        attention_output=self.attention(\n",
        "            inputs,inputs,attention_mask=mask\n",
        "        )\n",
        "        project_input=self.layernorm_1(inputs+attention_output)\n",
        "        project_output=self.dense_proj(project_input)\n",
        "\n",
        "        return self.layernorm_2(project_input+project_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asuNvD-cQSn_"
      },
      "source": [
        "# Transformer decorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vP9OTqcxQSn_"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim=embed_dim\n",
        "        self.dense_dim=dense_dim\n",
        "        self.num_heads=num_heads\n",
        "        self.attention_1=layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.attention_2=layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,key_dim=embed_dim)\n",
        "        self.dense_proj=keras.Sequential(\n",
        "            [layers.Dense(dense_dim,activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1=layers.LayerNormalization()\n",
        "        self.layernorm_2=layers.LayerNormalization()\n",
        "        self.layernorm_3=layers.LayerNormalization()\n",
        "        self.supports_masking=True\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_casual_attention_mask(self,inputs):\n",
        "        input_shape=tf.shape(inputs)\n",
        "        batch_size,sequence_length=input_shape[0],input_shape[1]\n",
        "        i=tf.range(sequence_length)[:,tf.newaxis]\n",
        "        j=tf.range(sequence_length)\n",
        "        mask=tf.cast(i>=j,dtype=\"int32\")\n",
        "        mask=tf.reshape(mask,(1,input_shape[1],input_shape[1]))\n",
        "        mult=tf.concat(\n",
        "            [tf.expand_dims(batch_size,-1),\n",
        "             tf.constant([1,1],dtype=tf.int32)],axis=0)\n",
        "\n",
        "        return tf.tile(mask,mult)\n",
        "\n",
        "\n",
        "    def call(self,inputs,encorder_outputs,mask=None):\n",
        "        casual_mask=self.get_casual_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask=tf.cast(\n",
        "                mask[:,tf.newaxis,:],dtype=\"int32\"\n",
        "            )\n",
        "            padding_mask=tf.minimum(padding_mask,casual_mask)\n",
        "        else:\n",
        "            padding_mask=mask\n",
        "        attention_output_1=self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=casual_mask\n",
        "        )\n",
        "        attention_output_1=self.layernorm_1(inputs+attention_output_1)\n",
        "        attention_output_2=self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encorder_outputs,\n",
        "            key=encorder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2=self.layernorm_2(\n",
        "            attention_output_1+attention_output_2\n",
        "        )\n",
        "        proj_output=self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2+proj_output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Dt2Pj_QSoA"
      },
      "source": [
        "# Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W8JH3MDzQSoA"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self,sequence_length,input_dim,output_dim,**kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings=layers.Embedding(\n",
        "            input_dim=input_dim,output_dim=output_dim)\n",
        "        self.position_embeddings=layers.Embedding(\n",
        "            input_dim=sequence_length,output_dim=output_dim)\n",
        "        self.sequence_length=sequence_length\n",
        "        self.input_dim=input_dim\n",
        "        self.output_dim=output_dim\n",
        "\n",
        "    def call(self,inputs):\n",
        "        length=tf.shape(inputs)[-1]\n",
        "        positions=tf.range(start=0,limit=length,delta=1)\n",
        "        embedded_tokens=self.token_embeddings(inputs)\n",
        "        embedded_positions=self.position_embeddings(positions)\n",
        "\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config=super(PositionalEmbedding,self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OJz24S2XQSoH"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.python.framework.ops import disable_eager_execution\n",
        "# disable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZN5UgCOQSoH"
      },
      "source": [
        "# End-to-End Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QYCGfZpwQSoH"
      },
      "outputs": [],
      "source": [
        "embed_dim=256\n",
        "dense_dim=2048\n",
        "num_heads=8\n",
        "\n",
        "encoder_inputs=keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(encoder_inputs)\n",
        "encoder_outputs=TransformerEncoder(embed_dim,dense_dim,num_heads)(x)\n",
        "\n",
        "decorder_inputs=keras.Input(shape=(None,),dtype=\"int64\",name=\"german\")\n",
        "x=PositionalEmbedding(sequence_length,vocab_size,embed_dim)(decorder_inputs)\n",
        "x=TransformerDecoder(embed_dim,dense_dim,num_heads)(x,encoder_outputs)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "decorder_outputs=layers.Dense(vocab_size,activation=\"softmax\")(x)\n",
        "transformer=keras.Model([encoder_inputs,decorder_inputs],decorder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_IQ5KACSRIa",
        "outputId": "9c8ca10c-5ff1-48d8-f690-9bd434aed97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " german (InputLayer)         [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            3845120   ['german[0][0]']              \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_1[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, None, 15000)          3855000   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XepQ7qXITPOP"
      },
      "source": [
        "# Training the sequence-to-sequence Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFQ2g7CYSdft",
        "outputId": "9c987820-9724-4c17-b26c-1ac132b490f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2424/2424 [==============================] - 179s 69ms/step - loss: 3.3727 - accuracy: 0.4947 - val_loss: 2.5744 - val_accuracy: 0.5793\n",
            "Epoch 2/50\n",
            "2424/2424 [==============================] - 161s 66ms/step - loss: 2.6219 - accuracy: 0.5827 - val_loss: 2.3320 - val_accuracy: 0.6184\n",
            "Epoch 3/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 2.4247 - accuracy: 0.6140 - val_loss: 2.2509 - val_accuracy: 0.6353\n",
            "Epoch 4/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 2.3109 - accuracy: 0.6333 - val_loss: 2.2019 - val_accuracy: 0.6471\n",
            "Epoch 5/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 2.2262 - accuracy: 0.6489 - val_loss: 2.1660 - val_accuracy: 0.6571\n",
            "Epoch 6/50\n",
            "2424/2424 [==============================] - 164s 68ms/step - loss: 2.1466 - accuracy: 0.6622 - val_loss: 2.1315 - val_accuracy: 0.6638\n",
            "Epoch 7/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 2.0883 - accuracy: 0.6722 - val_loss: 2.1233 - val_accuracy: 0.6650\n",
            "Epoch 8/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 2.0421 - accuracy: 0.6800 - val_loss: 2.1073 - val_accuracy: 0.6697\n",
            "Epoch 9/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 2.0008 - accuracy: 0.6876 - val_loss: 2.1247 - val_accuracy: 0.6710\n",
            "Epoch 10/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.9670 - accuracy: 0.6933 - val_loss: 2.1229 - val_accuracy: 0.6711\n",
            "Epoch 11/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.9365 - accuracy: 0.6983 - val_loss: 2.1155 - val_accuracy: 0.6735\n",
            "Epoch 12/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.9080 - accuracy: 0.7027 - val_loss: 2.1315 - val_accuracy: 0.6745\n",
            "Epoch 13/50\n",
            "2424/2424 [==============================] - 161s 67ms/step - loss: 1.8825 - accuracy: 0.7074 - val_loss: 2.1326 - val_accuracy: 0.6749\n",
            "Epoch 14/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.8592 - accuracy: 0.7110 - val_loss: 2.1265 - val_accuracy: 0.6741\n",
            "Epoch 15/50\n",
            "2424/2424 [==============================] - 165s 68ms/step - loss: 1.8353 - accuracy: 0.7151 - val_loss: 2.1417 - val_accuracy: 0.6764\n",
            "Epoch 16/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.8157 - accuracy: 0.7181 - val_loss: 2.1372 - val_accuracy: 0.6769\n",
            "Epoch 17/50\n",
            "2424/2424 [==============================] - 165s 68ms/step - loss: 1.7955 - accuracy: 0.7214 - val_loss: 2.1378 - val_accuracy: 0.6817\n",
            "Epoch 18/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.7775 - accuracy: 0.7247 - val_loss: 2.1363 - val_accuracy: 0.6786\n",
            "Epoch 19/50\n",
            "2424/2424 [==============================] - 164s 68ms/step - loss: 1.7594 - accuracy: 0.7272 - val_loss: 2.1462 - val_accuracy: 0.6791\n",
            "Epoch 20/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.7452 - accuracy: 0.7294 - val_loss: 2.1573 - val_accuracy: 0.6804\n",
            "Epoch 21/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.7305 - accuracy: 0.7323 - val_loss: 2.1628 - val_accuracy: 0.6797\n",
            "Epoch 22/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.7152 - accuracy: 0.7348 - val_loss: 2.1550 - val_accuracy: 0.6825\n",
            "Epoch 23/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.6996 - accuracy: 0.7373 - val_loss: 2.1600 - val_accuracy: 0.6840\n",
            "Epoch 24/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.6830 - accuracy: 0.7399 - val_loss: 2.1814 - val_accuracy: 0.6814\n",
            "Epoch 25/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.6693 - accuracy: 0.7423 - val_loss: 2.1946 - val_accuracy: 0.6844\n",
            "Epoch 26/50\n",
            "2424/2424 [==============================] - 161s 67ms/step - loss: 1.6558 - accuracy: 0.7446 - val_loss: 2.1869 - val_accuracy: 0.6839\n",
            "Epoch 27/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.6411 - accuracy: 0.7470 - val_loss: 2.2038 - val_accuracy: 0.6863\n",
            "Epoch 28/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.6250 - accuracy: 0.7496 - val_loss: 2.2129 - val_accuracy: 0.6831\n",
            "Epoch 29/50\n",
            "2424/2424 [==============================] - 161s 67ms/step - loss: 1.6134 - accuracy: 0.7515 - val_loss: 2.2124 - val_accuracy: 0.6832\n",
            "Epoch 30/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5989 - accuracy: 0.7540 - val_loss: 2.2302 - val_accuracy: 0.6835\n",
            "Epoch 31/50\n",
            "2424/2424 [==============================] - 161s 67ms/step - loss: 1.5863 - accuracy: 0.7562 - val_loss: 2.2397 - val_accuracy: 0.6846\n",
            "Epoch 32/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5721 - accuracy: 0.7585 - val_loss: 2.2543 - val_accuracy: 0.6833\n",
            "Epoch 33/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5616 - accuracy: 0.7603 - val_loss: 2.2366 - val_accuracy: 0.6878\n",
            "Epoch 34/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5476 - accuracy: 0.7628 - val_loss: 2.2540 - val_accuracy: 0.6872\n",
            "Epoch 35/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5376 - accuracy: 0.7646 - val_loss: 2.2772 - val_accuracy: 0.6857\n",
            "Epoch 36/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5253 - accuracy: 0.7664 - val_loss: 2.2612 - val_accuracy: 0.6881\n",
            "Epoch 37/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5144 - accuracy: 0.7687 - val_loss: 2.2561 - val_accuracy: 0.6871\n",
            "Epoch 38/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.5030 - accuracy: 0.7704 - val_loss: 2.2850 - val_accuracy: 0.6866\n",
            "Epoch 39/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.4892 - accuracy: 0.7726 - val_loss: 2.2835 - val_accuracy: 0.6854\n",
            "Epoch 40/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.4774 - accuracy: 0.7751 - val_loss: 2.3019 - val_accuracy: 0.6905\n",
            "Epoch 41/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.4656 - accuracy: 0.7773 - val_loss: 2.3263 - val_accuracy: 0.6859\n",
            "Epoch 42/50\n",
            "2424/2424 [==============================] - 167s 69ms/step - loss: 1.4538 - accuracy: 0.7787 - val_loss: 2.3376 - val_accuracy: 0.6886\n",
            "Epoch 43/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.4421 - accuracy: 0.7811 - val_loss: 2.3400 - val_accuracy: 0.6893\n",
            "Epoch 44/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.4332 - accuracy: 0.7825 - val_loss: 2.3505 - val_accuracy: 0.6887\n",
            "Epoch 45/50\n",
            "2424/2424 [==============================] - 163s 67ms/step - loss: 1.4215 - accuracy: 0.7845 - val_loss: 2.3422 - val_accuracy: 0.6905\n",
            "Epoch 46/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.4086 - accuracy: 0.7867 - val_loss: 2.3488 - val_accuracy: 0.6891\n",
            "Epoch 47/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.4007 - accuracy: 0.7883 - val_loss: 2.3961 - val_accuracy: 0.6887\n",
            "Epoch 48/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.3914 - accuracy: 0.7898 - val_loss: 2.3837 - val_accuracy: 0.6885\n",
            "Epoch 49/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.3812 - accuracy: 0.7917 - val_loss: 2.3866 - val_accuracy: 0.6899\n",
            "Epoch 50/50\n",
            "2424/2424 [==============================] - 162s 67ms/step - loss: 1.3714 - accuracy: 0.7935 - val_loss: 2.4156 - val_accuracy: 0.6890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b1a181958a0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "transformer.fit(train_data,epochs=50,validation_data=val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "C0zjU_ZqagVO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "ger_vocab = target_vectorization.get_vocabulary()\n",
        "ger_index_lookup = dict(zip(range(len(ger_vocab)), ger_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ger_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[End]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PY_wqakzcGB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18052fa1-2f4b-4cfa-8241-f9c797e246e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Tom will answer all of your questions.\n",
            "[start] tom wird alle fragen beantworten [end]  [end] [end] [end]          [end]\n",
            "-\n",
            "Both were intoxicated.\n",
            "[start] beide waren betrunken [end]  [end] [end] [end]          [end]  \n",
            "-\n",
            "Let's take a ten-minute break.\n",
            "[start] lasst uns eine halbe pause machen [end]  [end] [end]       [end]   \n",
            "-\n",
            "I thought Tom was Mary's boyfriend.\n",
            "[start] ich dachte tom wäre marias freund [end]  [end] [end] [end]         \n",
            "-\n",
            "I will continue.\n",
            "[start] ich werde [UNK] [end]  [end] [end] [end]  [end]          \n",
            "-\n",
            "That soil is rich in humus.\n",
            "[start] dieser boden ist reich in [UNK] [end]  [end] [end]    [end]      \n",
            "-\n",
            "Tom is younger than you think he is.\n",
            "[start] tom ist jünger als du denkst [end]  [end] [end] [end]      er   [end]\n",
            "-\n",
            "Tom hasn't yet returned to Australia.\n",
            "[start] tom ist noch nicht nach australien zurückgekommen [end]  [end] [end]         \n",
            "-\n",
            "I don't want to get a haircut.\n",
            "[start] ich möchte nicht die haare schneiden lassen [end]  [end] [end]         \n",
            "-\n",
            "I'm not sure what Tom is trying to say.\n",
            "[start] ich bin mir nicht sicher was tom zu sagen will [end]  [end] [end] [end]     \n",
            "-\n",
            "Tom was sitting next to me.\n",
            "[start] tom saß neben mir [end]  [end] [end] [end]           [end]\n",
            "-\n",
            "My father is worried about my health.\n",
            "[start] mein vater macht sich sorgen um meine gesundheit [end]  [end] wird [end]       \n",
            "-\n",
            "I never want to retire.\n",
            "[start] ich will nie in den ruhestand gehen [end]  [end] würde [end]        \n",
            "-\n",
            "Strange to say, I didn't notice it.\n",
            "[start] es ist für mich dass ich es nicht bemerkt habe [end]  [end] zu [end] [UNK] [end]   \n",
            "-\n",
            "Tom sat on the garbage can and played his harmonica.\n",
            "[start] tom saß an der [UNK] und sah maria auf seiner [UNK] [end]  [end] [end] [end]    [end]\n",
            "-\n",
            "Tom and Mary are very happy.\n",
            "[start] tom und maria sind sehr glücklich [end]  [end] [end] [end] [end]        \n",
            "-\n",
            "Only a fool would do something like that.\n",
            "[start] nur so ein narr würde so etwas zu machen [end]  [end] [end] [end]      \n",
            "-\n",
            "Do you want to sit?\n",
            "[start] wollen sie sich sitzen [end]  [end] [end] [end] [end]          \n",
            "-\n",
            "Do you really think that's wise?\n",
            "[start] glaubst du wirklich dass das ist [end]  [end] [end]        [end]  \n",
            "-\n",
            "He talks as if he knew everything.\n",
            "[start] er spricht alles so als ob er alles [UNK] [end]  [end] [end] [end]      \n"
          ]
        }
      ],
      "source": [
        "ger_eng_texts = [pair[0] for pair in german_test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(ger_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_YFgoVCYl_zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4be59d9-ac62-481f-d62c-d2026c53e4e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5ERUlhqdmwhn"
      },
      "outputs": [],
      "source": [
        "transformer.save('/content/drive/My Drive/Translators')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}